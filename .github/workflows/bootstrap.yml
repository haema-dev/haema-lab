name: "Step 1: Kubespray K8s"

on:
  workflow_dispatch:

jobs:
  setup:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - uses: actions/checkout@v3

      - name: ğŸŒ Connect to Tailscale
        uses: tailscale/github-action@v2
        with:
          version: 1.94.1
          authkey: ${{ secrets.TAILSCALE_AUTH_KEY }}

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Phase 1: Cleanup (FIRST_USERNAME)
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      - name: ğŸ§¹ Cleanup K8s
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.PROXMOX_VM_TAILSCALE_IP }}
          username: ${{ secrets.FIRST_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            set -e

            echo "ğŸ§¹ Cleanup Phase"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            USERNAME="${{ secrets.USERNAME }}"

            # 1. User shells restore
            echo "ğŸ”‘ Restoring user shells..."
            sudo usermod -s /bin/bash root || true
            sudo usermod -s /bin/bash "$USERNAME" || true

            # 2. ì„œë¹„ìŠ¤ ì¤‘ì§€
            echo "ğŸ›‘ Stopping services..."
            sudo systemctl stop kubelet 2>/dev/null || true
            sudo systemctl stop etcd 2>/dev/null || true
            sudo systemctl stop containerd 2>/dev/null || true
            sudo systemctl disable kubelet 2>/dev/null || true
            sudo systemctl disable etcd 2>/dev/null || true

            sleep 2

            # 3. í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
            echo "ğŸ”ª Killing processes..."
            for proc in kubelet apiserver etcd kube-controller-manager kube-scheduler kube-proxy coredns etcd-io containerd; do
              sudo pkill -9 $proc 2>/dev/null || true
            done

            sleep 2

            # 4. Kubernetes reset
            echo "ğŸ”„ Resetting Kubernetes..."
            sudo kubeadm reset --force 2>/dev/null || true

            # 5. ğŸ†• containerd ìºì‹œ ì‚­ì œ (ì´ë¯¸ì§€ ì €ì¥ì†Œ)
            echo "ğŸ—‘ï¸  Cleaning containerd cache..."
            sudo rm -rf /var/lib/containerd 2>/dev/null || true
            sudo rm -rf /run/containerd 2>/dev/null || true

            # 6. K8s ë°ì´í„° ì‚­ì œ
            echo "ğŸ—‚ï¸  Cleaning Kubernetes..."
            sudo rm -rf /etc/kubernetes
            sudo rm -rf /var/lib/kubelet
            sudo rm -rf /var/lib/etcd
            sudo rm -rf /var/lib/cni
            sudo rm -rf /etc/cni/net.d 2>/dev/null || true
            sudo rm -rf /var/lib/calico 2>/dev/null || true

            # 7. Kubespray cleanup
            echo "ğŸ“¦ Cleaning Kubespray..."
            [ -d /opt/kubespray ] && sudo rm -rf /opt/kubespray
            [ -d /opt/venv-kubespray ] && sudo rm -rf /opt/venv-kubespray

            # 8. Home directories cleanup
            echo "ğŸ  Cleaning home directories..."
            sudo rm -rf /home/$USERNAME/.kube
            sudo rm -rf /home/$USERNAME/.ansible
            sudo rm -rf /home/$USERNAME/.cache/pip 2>/dev/null || true

            # 9. Prepare /opt
            echo "ğŸ“ Preparing /opt..."
            sudo mkdir -p /opt
            sudo chown -R "$USERNAME:$USERNAME" /opt

            # 10. Configure sudoers
            echo "ğŸ” Configuring sudoers..."
            if ! sudo grep -q "^$USERNAME ALL=(ALL) NOPASSWD: ALL" /etc/sudoers.d/$USERNAME 2>/dev/null; then
              echo "$USERNAME ALL=(ALL) NOPASSWD: ALL" | sudo tee /etc/sudoers.d/$USERNAME > /dev/null
              sudo chmod 440 /etc/sudoers.d/$USERNAME
            fi

            # 11. Clean ports (ì¬ì‹œë„ ë¡œì§)
            echo "ğŸ”Œ Cleaning ports..."
            max_retries=3
            for attempt in $(seq 1 $max_retries); do
              sudo fuser -k -9 6443/tcp 2379/tcp 10250/tcp 10259/tcp 10257/tcp 8080/tcp 2>/dev/null || true
              sleep 1
              
              ports_in_use=$(sudo netstat -tlnp 2>/dev/null | grep -E '6443|2379|10250' | wc -l || echo 0)
              if [ $ports_in_use -eq 0 ]; then
                echo "âœ… All ports free"
                break
              fi
            done

            # 12. Hostname ì„¤ì •
            echo "ğŸ·ï¸  Setting hostname..."
            sudo hostnamectl set-hostname "${{ secrets.USERNAME }}"

            sleep 3
            echo "âœ… Cleanup complete"

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Phase 2: Setup (USERNAME)
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      - name: ğŸš€ Setup K8s with Kubespray
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.PROXMOX_VM_TAILSCALE_IP }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_USERNAME_PRIVATE_KEY }}
          script: |
            set -e

            echo "ğŸš€ Setup Phase"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            KUBE_VERSION="1.31.6"
            KUBESPRAY_VERSION="v2.29.0"
            KUBESPRAY_HOME="/opt/kubespray"
            VENV_PATH="/opt/venv-kubespray"
            HOST_IP="${{ secrets.HOST_IP }}"
            USERNAME="${{ secrets.USERNAME }}"


            # 1ï¸âƒ£ Cluster health check
            echo ""
            echo "ğŸ“Š Checking cluster health..."

            check_cluster_health() {
              if ! command -v kubectl &> /dev/null; then
                return 1
              fi
              
              if ! kubectl cluster-info &>/dev/null; then
                return 1
              fi
              
              READY_NODES=$(kubectl get nodes --no-headers 2>/dev/null | grep -c " Ready " || echo 0)
              TOTAL_NODES=$(kubectl get nodes --no-headers 2>/dev/null | wc -l || echo 0)
              
              if [ "$READY_NODES" -eq "$TOTAL_NODES" ] && [ "$TOTAL_NODES" -gt 0 ]; then
                return 0
              fi
              return 1
            }

            if check_cluster_health; then
              echo "âœ… Cluster is healthy - skipping setup"
              kubectl get nodes
              exit 0
            fi

            echo "âš ï¸  Cluster not ready, proceeding..."

            # 2ï¸âƒ£ Install dependencies
            echo ""
            echo "ğŸ“¦ Installing dependencies..."
            sudo apt-get update -qq
            sudo apt-get install -y -qq \
              python3-pip python3-venv git jq curl \
              2>&1 | grep -v "^Processing\|^done" || true

            # 3ï¸âƒ£ Setup Kubespray (fixed: removed sudo)
            echo ""
            echo "ğŸ“¥ Setting up Kubespray..."

            if [ -d "$KUBESPRAY_HOME/.git" ]; then
              CURRENT_VERSION=$(cd "$KUBESPRAY_HOME" && git describe --tags 2>/dev/null || echo "unknown")
              if [ "$CURRENT_VERSION" = "$KUBESPRAY_VERSION" ]; then
                echo "   âœ… Kubespray $KUBESPRAY_VERSION already cloned"
              else
                echo "   ğŸ”„ Updating from $CURRENT_VERSION to $KUBESPRAY_VERSION"
                cd "$KUBESPRAY_HOME"
                git fetch origin
                git checkout "$KUBESPRAY_VERSION"
              fi
            else
              echo "   ğŸ“¥ Cloning Kubespray..."
              git clone --depth 1 --branch "$KUBESPRAY_VERSION" \
                https://github.com/kubernetes-sigs/kubespray.git "$KUBESPRAY_HOME"
            fi

            # 4ï¸âƒ£ Python environment
            echo ""
            echo "ğŸ Setting up Python environment..."

            if [ ! -d "$VENV_PATH" ]; then
              python3 -m venv "$VENV_PATH"
            fi

            source "$VENV_PATH/bin/activate"
            pip install -q --upgrade pip
            pip install -q -r "$KUBESPRAY_HOME/requirements.txt"

            # 5ï¸âƒ£ Ansible inventory (fixed: removed sudo mkdir, fixed YAML indentation)
            echo ""
            echo "ğŸ“‹ Configuring Ansible inventory..."

            INVENTORY_DIR="$KUBESPRAY_HOME/inventory/mycluster"

            if [ -d "$INVENTORY_DIR" ]; then
              BACKUP_DIR="$KUBESPRAY_HOME/inventory/mycluster.backup.$(date +%s)"
              cp -r "$INVENTORY_DIR" "$BACKUP_DIR"
              echo "   âœ… Backed up existing inventory"
            fi

            mkdir -p "$INVENTORY_DIR/group_vars/all"

            # hosts.yaml (fixed: proper YAML indentation)
            cat > "$INVENTORY_DIR/hosts.yaml" << 'HOSTS'
            all:
              hosts:
                ${{ secrets.USERNAME }}:
                  ansible_connection: local
                  ansible_host: 127.0.0.1
              children:
                kube_control_plane:
                  hosts:
                    ${{ secrets.USERNAME }}:
                kube_node:
                  hosts:
                    ${{ secrets.USERNAME }}:
                etcd:
                  hosts:
                    ${{ secrets.USERNAME }}:
                k8s_cluster:
                  children:
                    kube_control_plane:
                    kube_node:
            HOSTS

            # all.yml
            cat > "$INVENTORY_DIR/group_vars/all/all.yml" << EOF
            kube_version: "1.31.6"
            container_manager: containerd
            dns_mode: coredns
            kube_pods_subnet: 10.244.0.0/16
            kube_service_addresses: 10.96.0.0/12

            # ğŸš¨ [ì¶”ê°€] í…Œì¼ìŠ¤ì¼€ì¼ MTU(1280)ì— ë§ì¶”ê¸° ìœ„í•œ ì„¤ì •
            calico_mtu: 1220
            veth_mtu: 1220

            kubelet_deployment_type: host
            kubeadm_init_timeout: 1800
            upgrade_cluster_setup_timeout: 1800
            skip_kubelet_systemd_environment_file_checks: true

            # ğŸ†• DNS ëª…ì‹œì  ì„¤ì •
            kube_dns_servers:
              - 10.96.0.10
            kubelet_cluster_dns: 10.96.0.10
            kubelet_extra_args: "--cluster-dns=10.96.0.10 --cluster-domain=cluster.local"

            # ğŸ†• CoreDNS ì„œë¹„ìŠ¤ IP ëª…ì‹œ
            dns_cluster_ip: "10.96.0.10"

            containerd_cgroup_driver: systemd
            kubelet_cgroup_driver: systemd

            apiserver_cert_extra_sans:
              - "localhost"
              - "127.0.0.1"
              - "$HOST_IP"
              - "kubernetes"
              - "kubernetes.default"
              - "kubernetes.default.svc"
              - "kubernetes.default.svc.cluster.local"
            EOF

            echo "   âœ… Inventory configured"

            # 6ï¸âƒ£ Run Kubespray
            echo ""
            echo "ğŸš€ Running Kubespray as root (15-20 minutes)..."

            cd "$KUBESPRAY_HOME"

            ansible-playbook \
              -i "$INVENTORY_DIR/hosts.yaml" \
              --become \
              --become-method=sudo \
              -e "kubeconfig_localhost=false" \
              -e "kubeconfig_server=https://${{ secrets.HOST_IP }}:6443" \
              -e "kube_owner=${{ secrets.USERNAME }}" \
              -v \
              cluster.yml

            if [ $? -ne 0 ]; then
              echo "âŒ Kubespray failed"
              exit 1
            fi

            echo "âœ… Kubespray completed"

            # 7ï¸âƒ£ Setup kubeconfig (fixed: proper sudo for root-owned files)
            echo ""
            echo "ğŸ”‘ Setting up kubeconfig..."

            KUBECONFIG_PATH="$HOME/.kube/config"

            mkdir -p "$(dirname "$KUBECONFIG_PATH")"

            # Copy root-owned file with sudo
            sudo cp /etc/kubernetes/admin.conf "$HOME/.kube/admin.conf.tmp"
            sudo chown $(whoami):$(whoami) "$HOME/.kube/admin.conf.tmp"

            # Patch server address
            sed -i "s|server:.*6443|server: https://$HOST_IP:6443|g" "$HOME/.kube/admin.conf.tmp"

            # Move to final location
            mv "$HOME/.kube/admin.conf.tmp" "$KUBECONFIG_PATH"

            sudo chown $(whoami):$(whoami) "$KUBECONFIG_PATH"
            chmod 600 "$KUBECONFIG_PATH"

            echo "   âœ… kubeconfig ready"

            # 8ï¸âƒ£ Verify cluster
            echo ""
            echo "âœ“ Verifying cluster..."

            export KUBECONFIG="$KUBECONFIG_PATH"

            kubectl cluster-info 2>/dev/null || echo "Cluster initializing..."
            echo ""
            kubectl get nodes || true
            echo ""
            kubectl get pods -n kube-system --no-headers 2>/dev/null | head -5 || true

            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ğŸ‰ Setup Phase Complete!"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            # 9ï¸âƒ£ Fix CoreDNS Service IP (ìë™ ìˆ˜ì •)
            # echo ""
            # echo "ğŸ”§ Fixing CoreDNS Service IP..."

            # export KUBECONFIG="$KUBECONFIG_PATH"

            # # 1. coredns â†’ kube-dnsë¡œ ë³€ê²½
            # kubectl delete svc coredns -n kube-system 2>/dev/null || true

            # # 2. ì˜¬ë°”ë¥¸ ì„¤ì •ìœ¼ë¡œ ì¬ìƒì„±
            # kubectl apply -f - << 'EOF'
            # apiVersion: v1
            # kind: Service
            # metadata:
            #   name: kube-dns
            #   namespace: kube-system
            #   labels:
            #     k8s-app: kube-dns
            #     kubernetes.io/cluster-service: "true"
            # spec:
            #   selector:
            #     k8s-app: kube-dns
            #   clusterIP: 10.96.0.10
            #   ports:
            #   - name: dns
            #     port: 53
            #     protocol: UDP
            #   - name: dns-tcp
            #     port: 53
            #     protocol: TCP
            # EOF

            # # 3. Pod ì¬ì‹œì‘
            # kubectl delete pod -n kube-system -l k8s-app=kube-dns

            # echo "âœ… CoreDNS Service IP fixed to 10.96.0.10"

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Phase 3: Verification (FIRST_USERNAME)
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      - name: ğŸ’ Post-Setup Verification
        if: always()
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.PROXMOX_VM_TAILSCALE_IP }}
          username: ${{ secrets.FIRST_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            set -e

            echo "âœ“ Post-Setup Verification"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            USERNAME="${{ secrets.USERNAME }}"

            # Check shells
            echo "ğŸ” Checking user shells..."
            ROOT_SHELL=$(grep ^root /etc/passwd | cut -d: -f7)
            USER_SHELL=$(grep ^$USERNAME /etc/passwd | cut -d: -f7)

            if [[ "$ROOT_SHELL" == *"nologin"* ]]; then
              sudo usermod -s /bin/bash ${{ secrets.FIRST_USERNAME }}
            fi

            if [[ "$USER_SHELL" == *"nologin"* ]]; then
              sudo usermod -s /bin/bash "$USERNAME"
            fi

            echo "   root: $ROOT_SHELL"
            echo "   $USERNAME: $USER_SHELL"

            # Check ownership
            echo ""
            echo "ğŸ“‚ File ownership:"
            echo "   /opt/kubespray: $(ls -ld /opt/kubespray 2>/dev/null | awk '{print $3, $4}')"
            echo "   /opt/venv-kubespray: $(ls -ld /opt/venv-kubespray 2>/dev/null | awk '{print $3, $4}')"

            # Check K8s
            echo ""
            echo "ğŸ“Š Kubernetes Status:"
            sudo -u "$USERNAME" -H bash << 'K8S_CHECK'
            export KUBECONFIG="$HOME/.kube/config"
            echo "   Nodes: $(kubectl get nodes --no-headers 2>/dev/null | wc -l)"
            echo "   Pods: $(kubectl get pods -n kube-system --no-headers 2>/dev/null | wc -l)"
            K8S_CHECK

            echo ""
            echo "âœ… Verification complete"
